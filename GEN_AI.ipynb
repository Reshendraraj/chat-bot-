{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN4BkpaR6zyP",
        "outputId": "1b30a769-bb44-4a08-fc44-93526ecc7eb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.44)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain langchain-google-genai google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] =\"your api key\"\n"
      ],
      "metadata": {
        "id": "BL9M4tnb6-7b"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "response = model([HumanMessage(content=\"Tell me a joke!\")])\n",
        "print(response.content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmoCSAUR7RZV",
        "outputId": "312e22a7-547d-4f83-8cbf-7a9367fde5ab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't scientists trust atoms? \n",
            "\n",
            "Because they make up everything!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHATBOT on top of gemini using Langchain"
      ],
      "metadata": {
        "id": "4DCwuE_UFzb8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zChdkX05Fyv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"your api key\")\n",
        "\n",
        "models = genai.list_models()\n",
        "for model in models:\n",
        "    print(model.name, \"-\", model.supported_generation_methods)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "eAj5GT1S7Fmo",
        "outputId": "f5456d35-c9a3-49c5-e9f9-0e0c9455d4fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-16 13:05:32.978 200 GET /v1beta/models?pageSize=50&%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2713.80ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001 - ['generateMessage', 'countMessageTokens']\n",
            "models/text-bison-001 - ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
            "models/embedding-gecko-001 - ['embedText', 'countTextTokens']\n",
            "models/gemini-1.0-pro-vision-latest - ['generateContent', 'countTokens']\n",
            "models/gemini-pro-vision - ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-latest - ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-001 - ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro-002 - ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro - ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-latest - ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-001 - ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-001-tuning - ['generateContent', 'countTokens', 'createTunedModel']\n",
            "models/gemini-1.5-flash - ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-002 - ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-8b - ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-001 - ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-latest - ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-exp-0827 - ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-exp-0924 - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-exp - ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-001 - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-exp-image-generation - ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-lite-001 - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-lite - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-lite-preview-02-05 - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-lite-preview - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-pro-exp - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-pro-exp-02-05 - ['generateContent', 'countTokens']\n",
            "models/gemini-exp-1206 - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-thinking-exp-01-21 - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-thinking-exp - ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-thinking-exp-1219 - ['generateContent', 'countTokens']\n",
            "models/learnlm-1.5-pro-experimental - ['generateContent', 'countTokens']\n",
            "models/gemma-3-27b-it - ['generateContent', 'countTokens']\n",
            "models/embedding-001 - ['embedContent']\n",
            "models/text-embedding-004 - ['embedContent']\n",
            "models/gemini-embedding-exp-03-07 - ['embedContent']\n",
            "models/gemini-embedding-exp - ['embedContent']\n",
            "models/aqa - ['generateAnswer']\n",
            "models/imagen-3.0-generate-002 - ['predict']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "0sKidzMV7I3p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your api key\"\n",
        "\n",
        "# Load Gemini model\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Memory to store chat history\n",
        "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
        "\n",
        "# Define a chatbot prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"],\n",
        "    template=\"You are a friendly chatbot. Here is the conversation so far: {history}\\nUser: {input}\\nAssistant:\"\n",
        ")\n",
        "\n",
        "# Create the chatbot chain\n",
        "chatbot = LLMChain(llm=model, prompt=prompt, memory=memory)\n",
        "\n",
        "# Start chatting!\n",
        "print(\"Chatbot is ready! Type 'exit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"bye!\")\n",
        "        break\n",
        "    response = chatbot.run(user_input)\n",
        "    print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODbTgj3wEq_J",
        "outputId": "55b84f95-9ac3-42b8-8bca-ee76fd7127f3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot is ready! Type 'exit' to stop.\n",
            "\n",
            "You: hi\n",
            "Bot: Hi there! How can I help you today?\n",
            "You: translate how are you in germany\n",
            "Bot: The most common way to say \"How are you?\" in German is \"Wie geht es dir?\" (informal, singular) or \"Wie geht es Ihnen?\" (formal, singular).  You could also use \"Wie geht's?\" which is a shortened, more casual version.\n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "* **Wie geht es dir?** (Vee gate ess deer?) - How are you? (Informal, used with friends, family, and people you know well)\n",
            "* **Wie geht es Ihnen?** (Vee gate ess eenen?) - How are you? (Formal, used with strangers, older people, superiors, and in professional settings)\n",
            "* **Wie geht's?** (Vee gates?) - How's it going? (Informal, short form)\n",
            "\n",
            "\n",
            "You can also use these alternatives:\n",
            "\n",
            "* **Alles klar?** (Alles klahr?) - Everything alright? (Informal)\n",
            "* **Was macht man so?** (Vas macht man zo?) - What are you up to? (Informal)\n",
            "\n",
            "\n",
            "So, depending on the context, you can choose the most appropriate phrase.\n",
            "You: wow tha's great\n",
            "Bot: You're welcome!  I'm glad I could help. Is there anything else I can translate for you or any other questions you have?\n",
            "You: exit\n",
            "bye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install gradio\n"
      ],
      "metadata": {
        "id": "lYHt9c1oE8j6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import gradio as gr\n",
        "\n",
        "# def chat(user_input, history=[]):\n",
        "#     response = chatbot.run(user_input)\n",
        "#     history.append((user_input, response))\n",
        "#     return response, history\n",
        "\n",
        "# gr.ChatInterface(fn=chat).launch()\n"
      ],
      "metadata": {
        "id": "pahrVpJRG-Mh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IqyE5lX7I4am"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}